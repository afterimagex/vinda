{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "import deeplake\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = deeplake.ingest_classification(\n",
    "    src = '../data/cifar10', \n",
    "    dest = \"s3://classification/cifar10-99\", \n",
    "    num_workers=4,\n",
    "    dest_creds = {\n",
    "        \"aws_access_key_id\": \"wxgn3BIy2ghFhQfRDe68\", \n",
    "        \"aws_secret_access_key\": \"W3rKG6qe75xqgkUiuMXct7QVis1tPFfT9BxZpFD7\",\n",
    "        \"endpoint_url\": \"http://172.24.181.62:8588\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://classification/cifar10-99 loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blank/miniconda3/envs/shikra/lib/python3.10/site-packages/deeplake/integrations/pytorch/common.py:137: UserWarning: Decode method for tensors ['train/images', 'val/images'] is defaulting to numpy. Please consider specifying a decode_method in .pytorch() that maximizes the data preprocessing speed based on your transformation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(key='train/images', index=Index([0]))\n"
     ]
    },
    {
     "ename": "non_hub_storage_error",
     "evalue": "\u001b[31m\tHigh-Performance Features are only available for datasets that are connected to Deep Lake and have a path\n    hub://org_id/dataset_name. Please generate this path by connecting the dataset to Deep Lake using deeplake.connect().\n    Further details are available here: https://docs.activeloop.ai/storage-and-credentials/managed-credentials\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mnon_hub_storage_error\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(ds\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mimages[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# a = ds.train.dataloader()\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(a)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mdataloader():\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mdata())\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/shikra/lib/python3.10/site-packages/deeplake/enterprise/dataloader.py:910\u001b[0m, in \u001b[0;36mDeepLakeDataLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator)\n",
      "File \u001b[0;32m~/miniconda3/envs/shikra/lib/python3.10/site-packages/indra/pytorch/loader.py:100\u001b[0m, in \u001b[0;36mLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m         indexes \u001b[38;5;241m=\u001b[39m get_indexes(dataset)\n\u001b[1;32m     98\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m dataset[indexes]\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_tensors\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_tensors\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson_tensors\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpil_compressed_tensors\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n",
      "File \u001b[0;32m~/miniconda3/envs/shikra/lib/python3.10/site-packages/indra/pytorch/loader.py:225\u001b[0m, in \u001b[0;36mcreate_dataloader\u001b[0;34m(dataset, batch_size, num_threads, tensors, raw_tensors, drop_last, return_index, ignore_errors, offset)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_dataloader\u001b[39m(\n\u001b[1;32m    214\u001b[0m     dataset,\n\u001b[1;32m    215\u001b[0m     batch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m     offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    223\u001b[0m ):\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_threads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m            \u001b[49m\u001b[43mraw_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mloader(\n\u001b[1;32m    236\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    237\u001b[0m         num_threads\u001b[38;5;241m=\u001b[39mnum_threads,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         offset\u001b[38;5;241m=\u001b[39moffset \u001b[38;5;28;01mif\u001b[39;00m offset \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    244\u001b[0m     )\n",
      "\u001b[0;31mnon_hub_storage_error\u001b[0m: \u001b[31m\tHigh-Performance Features are only available for datasets that are connected to Deep Lake and have a path\n    hub://org_id/dataset_name. Please generate this path by connecting the dataset to Deep Lake using deeplake.connect().\n    Further details are available here: https://docs.activeloop.ai/storage-and-credentials/managed-credentials\u001b[0m"
     ]
    }
   ],
   "source": [
    "ds = deeplake.load(\"s3://classification/cifar10-99\", token='123', creds = {\n",
    "        \"aws_access_key_id\": \"wxgn3BIy2ghFhQfRDe68\", \n",
    "        \"aws_secret_access_key\": \"W3rKG6qe75xqgkUiuMXct7QVis1tPFfT9BxZpFD7\",\n",
    "        \"endpoint_url\": \"http://172.24.181.62:8588\",\n",
    "    })\n",
    "\n",
    "print(ds.train.images[0])\n",
    "\n",
    "# a = ds.train.dataloader()\n",
    "# print(a)\n",
    "\n",
    "for x in ds.dataloader():\n",
    "    print(x.data())\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shikra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
